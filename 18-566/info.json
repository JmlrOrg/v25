{
    "abstract": "While machine learning is traditionally a resource intensive task, embedded systems, autonomous navigation, and the vision of the Internet of Things fuel the interest in resource-efficient approaches. These approaches aim for a carefully chosen trade-off between performance and resource consumption in terms of computation and energy. The development of such approaches is among the major challenges in current machine learning research and key to ensure a smooth transition of machine learning technology from a scientific environment with virtually unlimited computing resources into everyday's applications. In this article, we provide an overview of the current state of the art of machine learning techniques facilitating these real-world requirements. In particular, we focus on resource-efficient inference based on deep neural networks (DNNs), the predominant machine learning models of the past decade. We give a comprehensive overview of the vast literature that can be mainly split into three non-mutually exclusive categories: (i) quantized neural networks, (ii) network pruning, and (iii) structural efficiency. These techniques can be applied during training or as post-processing, and they are widely used to reduce the computational demands in terms of memory footprint, inference speed, and energy efficiency. We also briefly discuss different concepts of embedded hardware for DNNs and their compatibility with machine learning techniques as well as potential for energy and latency reduction. We substantiate our discussion with experiments on well-known benchmark data sets using compression techniques (quantization, pruning) for a set of resource-constrained embedded systems, such as CPUs, GPUs and FPGAs. The obtained results highlight the difficulty of finding good trade-offs between resource efficiency and prediction quality.",
    "authors": [
        "Wolfgang Roth",
        "G\u00fcnther Schindler",
        "Bernhard Klein",
        "Robert Peharz",
        "Sebastian Tschiatschek",
        "Holger Fr{{\\\"o}}ning",
        "Franz Pernkopf",
        "Zoubin Ghahramani"
    ],
    "emails": [
        "roth@tugraz.at",
        "guenther.schindler@ziti.uni-heidelberg.de",
        "bernhard.klein@ziti.uni-heidelberg.de",
        "robert.peharz@tugraz.at",
        "sebastian.tschiatschek@univie.ac.at",
        "holger.froening@ziti.uni-heidelberg.de",
        "pernkopf@tugraz.at",
        "zoubin@eng.cam.ac.uk"
    ],
    "id": "18-566",
    "issue": 50,
    "pages": [
        1,
        51
    ],
    "title": "Resource-Efficient Neural Networks for Embedded Systems",
    "volume": 25,
    "year": 2024
}
{
    "abstract": "Network lasso (NL for short) is a technique for estimating models by simultaneously clustering data samples and fitting the models to them. It often succeeds in forming clusters thanks to the geometry of the sum of $\\ell_2$ norm employed therein, but there may be limitations due to the convexity of the regularizer. This paper focuses on clustering generated by NL and strengthens it by creating a non-convex extension, called network trimmed lasso (NTL for short). Specifically, we initially investigate a sufficient condition that guarantees the recovery of the latent cluster structure of NL on the basis of the result of Sun et al. (2021) for convex clustering, which is a special case of NL for ordinary clustering. Second, we extend NL to NTL to incorporate a cardinality (or, $\\ell_0$-)constraint and rewrite the constrained optimization problem defined with the $\\ell_0$ norm, a discontinuous function, into an equivalent unconstrained continuous optimization problem. We develop ADMM algorithms to solve NTL and show their convergence results. Numerical illustrations indicate that the non-convex extension provides a more clear-cut cluster structure when NL fails to form clusters without incorporating prior knowledge of the associated parameters.",
    "authors": [
        "Shotaro Yagishita",
        "Jun-ya Gotoh"
    ],
    "emails": [
        "a15.fjng@g.chuo-u.ac.jp",
        "jgoto@kc.chuo-u.ac.jp"
    ],
    "id": "21-1190",
    "issue": 21,
    "pages": [
        1,
        42
    ],
    "title": "Pursuit of the Cluster Structure of Network Lasso: Recovery Condition and Non-convex Extension",
    "volume": 25,
    "year": 2024
}
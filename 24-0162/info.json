{
    "abstract": "There is a mystery at the heart of operator learning: how can one recover a non-self-adjoint operator from data without probing the adjoint? Current practical approaches suggest that one can accurately recover an operator while only using data generated by the forward action of the operator without access to the adjoint. However, naively, it seems essential to sample the action of the adjoint. In this paper, we partially explain this mystery by proving that without querying the adjoint, one can approximate a family of non-self-adjoint infinite-dimensional compact operators via projection onto a Fourier basis.  We then apply the result to recovering Green's functions of elliptic partial differential operators and derive an adjoint-free sample complexity bound. While existing theory justifies low sample complexity in operator learning, ours is the first adjoint-free analysis that attempts to close the gap between theory and practice.",
    "authors": [
        "Nicolas Boull{{\\'e}}",
        "Diana Halikias",
        "Samuel E. Otto",
        "Alex Townsend"
    ],
    "emails": [
        "n.boulle@imperial.ac.uk",
        "dh736@cornell.edu",
        "s.otto@cornell.com",
        "townsend@cornell.edu"
    ],
    "extra_links": [
        [
            "code",
            "https://github.com/NBoulle/OperatorLearningAdjoint"
        ]
    ],
    "id": "24-0162",
    "issue": 364,
    "pages": [
        1,
        54
    ],
    "title": "Operator learning without the adjoint",
    "volume": 25,
    "year": 2024
}
{
    "abstract": "This paper studies the binary classification of unbounded data from ${\\mathbb R}^d$ generated under Gaussian Mixture Models (GMMs) using deep ReLU neural networks. We obtain \u2014 for the first time \u2014 non-asymptotic upper bounds and convergence rates of the excess risk (excess misclassification error) for the classification without restrictions on model parameters. While the majority of existing generalization analysis of classification algorithms relies on a bounded domain, we consider an unbounded domain by leveraging the analyticity and fast decay of Gaussian distributions. To facilitate our analysis, we give a novel approximation error bound for general analytic functions using ReLU networks, which may be of independent interest. Gaussian distributions can be adopted nicely to model data arising in applications, e.g., speeches, images, and texts; our results provide a theoretical verification of the observed efficiency of deep neural networks in practical classification problems.",
    "authors": [
        "Tian-Yi Zhou",
        "Xiaoming Huo"
    ],
    "emails": [
        "tzhou306@gatech.edu",
        "huo@isye.gatech.edu"
    ],
    "id": "23-0957",
    "issue": 190,
    "pages": [
        1,
        54
    ],
    "title": "Classification of Data Generated by Gaussian Mixture Models Using Deep ReLU Networks",
    "volume": 25,
    "year": 2024
}